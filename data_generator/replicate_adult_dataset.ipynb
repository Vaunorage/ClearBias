{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-04T17:09:14.586795Z",
     "start_time": "2024-12-04T17:09:08.355060Z"
    }
   },
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "adult = fetch_ucirepo(id=2)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T17:09:14.607764Z",
     "start_time": "2024-12-04T17:09:14.594931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = adult['data']['original']\n",
    "df"
   ],
   "id": "90f8e46b119f0b1b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       age         workclass  fnlwgt  education  education-num  \\\n",
       "0       39         State-gov   77516  Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2       38           Private  215646    HS-grad              9   \n",
       "3       53           Private  234721       11th              7   \n",
       "4       28           Private  338409  Bachelors             13   \n",
       "...    ...               ...     ...        ...            ...   \n",
       "48837   39           Private  215419  Bachelors             13   \n",
       "48838   64               NaN  321403    HS-grad              9   \n",
       "48839   38           Private  374983  Bachelors             13   \n",
       "48840   44           Private   83891  Bachelors             13   \n",
       "48841   35      Self-emp-inc  182148  Bachelors             13   \n",
       "\n",
       "           marital-status         occupation    relationship  \\\n",
       "0           Never-married       Adm-clerical   Not-in-family   \n",
       "1      Married-civ-spouse    Exec-managerial         Husband   \n",
       "2                Divorced  Handlers-cleaners   Not-in-family   \n",
       "3      Married-civ-spouse  Handlers-cleaners         Husband   \n",
       "4      Married-civ-spouse     Prof-specialty            Wife   \n",
       "...                   ...                ...             ...   \n",
       "48837            Divorced     Prof-specialty   Not-in-family   \n",
       "48838             Widowed                NaN  Other-relative   \n",
       "48839  Married-civ-spouse     Prof-specialty         Husband   \n",
       "48840            Divorced       Adm-clerical       Own-child   \n",
       "48841  Married-civ-spouse    Exec-managerial         Husband   \n",
       "\n",
       "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                   White    Male          2174             0              40   \n",
       "1                   White    Male             0             0              13   \n",
       "2                   White    Male             0             0              40   \n",
       "3                   Black    Male             0             0              40   \n",
       "4                   Black  Female             0             0              40   \n",
       "...                   ...     ...           ...           ...             ...   \n",
       "48837               White  Female             0             0              36   \n",
       "48838               Black    Male             0             0              40   \n",
       "48839               White    Male             0             0              50   \n",
       "48840  Asian-Pac-Islander    Male          5455             0              40   \n",
       "48841               White    Male             0             0              60   \n",
       "\n",
       "      native-country  income  \n",
       "0      United-States   <=50K  \n",
       "1      United-States   <=50K  \n",
       "2      United-States   <=50K  \n",
       "3      United-States   <=50K  \n",
       "4               Cuba   <=50K  \n",
       "...              ...     ...  \n",
       "48837  United-States  <=50K.  \n",
       "48838  United-States  <=50K.  \n",
       "48839  United-States  <=50K.  \n",
       "48840  United-States  <=50K.  \n",
       "48841  United-States   >50K.  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 15 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T17:09:15.445178Z",
     "start_time": "2024-12-04T17:09:15.410893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr, gaussian_kde\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def is_numeric_column(series: pd.Series) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a column should be treated as numeric for KDE.\n",
    "    \"\"\"\n",
    "    if not np.issubdtype(series.dtype, np.number):\n",
    "        return False\n",
    "\n",
    "    n_unique = len(series.dropna().unique())\n",
    "    return n_unique >= 5\n",
    "\n",
    "\n",
    "def is_integer_column(series: pd.Series) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a numeric column contains only integers.\n",
    "    \"\"\"\n",
    "    return np.all(series.dropna() == series.dropna().astype(int))\n",
    "\n",
    "\n",
    "def get_unique_samples(kde: gaussian_kde, n_samples: int, is_integer: bool = False,\n",
    "                       max_attempts: int = 1000) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get unique samples from KDE with appropriate type handling.\n",
    "    \"\"\"\n",
    "    samples = kde.resample(min(n_samples * 2, max_attempts))[0]\n",
    "\n",
    "    if is_integer:\n",
    "        samples = np.round(samples).astype(int)\n",
    "\n",
    "    unique_samples = np.unique(samples)\n",
    "\n",
    "    attempts = 1\n",
    "    while len(unique_samples) < n_samples and attempts < max_attempts:\n",
    "        new_samples = kde.resample(n_samples)[0]\n",
    "        if is_integer:\n",
    "            new_samples = np.round(new_samples).astype(int)\n",
    "        unique_samples = np.unique(np.concatenate([unique_samples, new_samples]))\n",
    "        attempts += 1\n",
    "\n",
    "    if len(unique_samples) > n_samples:\n",
    "        indices = np.linspace(0, len(unique_samples) - 1, n_samples).astype(int)\n",
    "        unique_samples = np.sort(unique_samples)[indices]\n",
    "\n",
    "    return unique_samples\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataSchema:\n",
    "    attr_categories: List[List[Union[int, float]]]  # Now starts from 0\n",
    "    protected_attr: List[str]\n",
    "    attr_names: List[str]\n",
    "    binning_info: Dict[str, Dict[str, Union[List[float], str]]]\n",
    "    kde_distributions: Dict[str, gaussian_kde]\n",
    "    label_encoders: Dict[str, LabelEncoder]\n",
    "    category_maps: Dict[str, Dict[Union[int, float], str]]\n",
    "\n",
    "\n",
    "def create_kde_encoding(series: pd.Series, n_samples: int = 100) -> Tuple[\n",
    "    np.ndarray, gaussian_kde, List[Union[int, float]], Dict[Union[int, float], str]]:\n",
    "    \"\"\"\n",
    "    Create KDE from the series and sample fixed points from it.\n",
    "    \"\"\"\n",
    "    non_nan_mask = pd.notna(series)\n",
    "    values = series[non_nan_mask].to_numpy()\n",
    "\n",
    "    if len(values) == 0:\n",
    "        return np.full(len(series), -1), None, [-1, 0], {-1: 'nan', 0: '0'}\n",
    "\n",
    "    kde = gaussian_kde(values)\n",
    "    is_integer = is_integer_column(series)\n",
    "    sampled_points = get_unique_samples(kde, n_samples, is_integer)\n",
    "\n",
    "    # Create categories starting from -1 (missing) then 0 to n-1\n",
    "    categories = [-1] + list(range(len(sampled_points)))\n",
    "\n",
    "    # Create mapping dictionary\n",
    "    if is_integer:\n",
    "        category_map = {-1: 'nan',\n",
    "                        **{i: str(int(point)) for i, point in zip(range(len(sampled_points)), sampled_points)}}\n",
    "    else:\n",
    "        category_map = {-1: 'nan',\n",
    "                        **{i: f\"{point:.3f}\" for i, point in zip(range(len(sampled_points)), sampled_points)}}\n",
    "\n",
    "    # Encode original values\n",
    "    encoded = np.full(len(series), -1)  # Default to -1 for missing values\n",
    "    for i, val in enumerate(series[non_nan_mask]):\n",
    "        nearest_idx = np.abs(sampled_points - val).argmin()\n",
    "        encoded[non_nan_mask][i] = nearest_idx  # Now starts from 0\n",
    "\n",
    "    return encoded, kde, categories, category_map\n",
    "\n",
    "\n",
    "def generate_schema_from_dataframe(\n",
    "        df: pd.DataFrame,\n",
    "        protected_columns: List[str] = None,\n",
    "        attr_prefix: str = None,\n",
    "        outcome_column: str = 'outcome',\n",
    "        ensure_positive_definite: bool = True,\n",
    "        n_samples: int = 100\n",
    ") -> Tuple[DataSchema, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generate a DataSchema and correlation matrix from a pandas DataFrame using KDE for numeric columns.\n",
    "    \"\"\"\n",
    "    if outcome_column not in df.columns:\n",
    "        raise ValueError(f\"Outcome column '{outcome_column}' not found in DataFrame\")\n",
    "\n",
    "    if attr_prefix:\n",
    "        attr_columns = [col for col in df.columns if col.startswith(attr_prefix)]\n",
    "    else:\n",
    "        attr_columns = [col for col in df.columns if col != outcome_column]\n",
    "\n",
    "    if not attr_columns:\n",
    "        raise ValueError(\"No attribute columns found\")\n",
    "\n",
    "    attr_categories = []\n",
    "    encoded_df = pd.DataFrame(index=df.index)\n",
    "    binning_info = {}\n",
    "    kde_distributions = {}\n",
    "    label_encoders = {}\n",
    "    category_maps = {}\n",
    "\n",
    "    for col in attr_columns:\n",
    "        if is_numeric_column(df[col]):\n",
    "            encoded_vals, kde, categories, category_map = create_kde_encoding(df[col], n_samples)\n",
    "\n",
    "            encoded_df[col] = encoded_vals\n",
    "            attr_categories.append(categories)  # Now contains [-1, 0, 1, ..., n-1]\n",
    "            category_maps[col] = category_map\n",
    "\n",
    "            if kde is not None:\n",
    "                kde_distributions[col] = kde\n",
    "                binning_info[col] = {\n",
    "                    'strategy': 'kde',\n",
    "                    'n_samples': n_samples,\n",
    "                    'is_integer': is_integer_column(df[col])\n",
    "                }\n",
    "\n",
    "        else:\n",
    "            le = LabelEncoder()\n",
    "            non_nan_vals = df[col].dropna().unique()\n",
    "\n",
    "            if len(non_nan_vals) > 0:\n",
    "                str_vals = [str(x) for x in non_nan_vals]\n",
    "                str_vals = list(dict.fromkeys(str_vals))\n",
    "\n",
    "                le.fit(str_vals)\n",
    "                encoded = np.full(len(df), -1)  # Default to -1 for missing values\n",
    "\n",
    "                mask = df[col].notna()\n",
    "                if mask.any():\n",
    "                    encoded[mask] = le.transform([str(x) for x in df[col][mask]])  # Now starts from 0\n",
    "\n",
    "                # Store encoded categories and mapping\n",
    "                categories = [-1] + list(range(len(str_vals)))  # [-1, 0, 1, ..., n-1]\n",
    "                category_map = {-1: 'nan', **{i: val for i, val in enumerate(str_vals)}}\n",
    "\n",
    "                label_encoders[col] = le\n",
    "                category_maps[col] = category_map\n",
    "            else:\n",
    "                encoded = np.full(len(df), -1)\n",
    "                categories = [-1, 0]  # Always include 0 even if empty\n",
    "                category_map = {-1: 'nan', 0: 'empty'}\n",
    "\n",
    "            encoded_df[col] = encoded\n",
    "            attr_categories.append(categories)\n",
    "\n",
    "    # Rest of the function remains the same...\n",
    "    if protected_columns is None:\n",
    "        protected_attr = [False] * len(attr_columns)\n",
    "    else:\n",
    "        invalid_cols = [col for col in protected_columns if col not in attr_columns]\n",
    "        if invalid_cols:\n",
    "            raise ValueError(f\"Protected columns {invalid_cols} not found in attributes\")\n",
    "        protected_attr = [col in protected_columns for col in attr_columns]\n",
    "\n",
    "    correlation_matrix = np.zeros((len(attr_columns), len(attr_columns)))\n",
    "    for i, col1 in enumerate(attr_columns):\n",
    "        for j, col2 in enumerate(attr_columns):\n",
    "            if i == j:\n",
    "                correlation_matrix[i, j] = 1.0\n",
    "            else:\n",
    "                # Update mask to check for non-zero values\n",
    "                mask = (encoded_df[col1] > 0) & (encoded_df[col2] > 0)\n",
    "                if mask.any():\n",
    "                    corr, _ = spearmanr(encoded_df[col1][mask], encoded_df[col2][mask])\n",
    "                    correlation_matrix[i, j] = corr if not np.isnan(corr) else 0.0\n",
    "                    correlation_matrix[j, i] = correlation_matrix[i, j]\n",
    "                else:\n",
    "                    correlation_matrix[i, j] = 0.0\n",
    "                    correlation_matrix[j, i] = 0.0\n",
    "\n",
    "    if ensure_positive_definite:\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(correlation_matrix)\n",
    "        if np.any(eigenvalues < 0):\n",
    "            eigenvalues[eigenvalues < 0] = 1e-6\n",
    "            correlation_matrix = eigenvectors @ np.diag(eigenvalues) @ eigenvectors.T\n",
    "            scaling = np.sqrt(np.diag(correlation_matrix))\n",
    "            correlation_matrix = correlation_matrix / scaling[:, None] / scaling[None, :]\n",
    "\n",
    "    schema = DataSchema(\n",
    "        attr_categories=attr_categories,\n",
    "        protected_attr=protected_attr,\n",
    "        attr_names=attr_columns,\n",
    "        binning_info=binning_info,\n",
    "        kde_distributions=kde_distributions,\n",
    "        label_encoders=label_encoders,\n",
    "        category_maps=category_maps\n",
    "    )\n",
    "\n",
    "    return schema, correlation_matrix\n",
    "\n",
    "\n",
    "def decode_dataframe(df: pd.DataFrame, schema: DataSchema) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Decode a dataframe using the schema's category maps.\n",
    "    \"\"\"\n",
    "    decoded_df = pd.DataFrame(index=df.index)\n",
    "\n",
    "    for col in schema.attr_names:\n",
    "        if col in df.columns:\n",
    "            category_map = schema.category_maps[col]\n",
    "            decoded_df[col] = df[col].map(lambda x: category_map.get(x, category_map[0]))\n",
    "\n",
    "    return decoded_df"
   ],
   "id": "4f7ba6f55dde300f",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T17:09:31.145102Z",
     "start_time": "2024-12-04T17:09:16.127923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "schema, corr_matrix = generate_schema_from_dataframe(df, protected_columns=['race', 'sex'], outcome_column='income',\n",
    "                                                     n_samples=10)"
   ],
   "id": "9eb8380998cdadd4",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T17:10:03.972770Z",
     "start_time": "2024-12-04T17:10:03.960974Z"
    }
   },
   "cell_type": "code",
   "source": "schema",
   "id": "13cacaf94aec9551",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataSchema(attr_categories=[[-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8], [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [-1, 0, 1, 2, 3, 4, 5, 6], [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], [-1, 0, 1, 2, 3, 4, 5], [-1, 0, 1, 2, 3, 4], [-1, 0, 1], [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]], protected_attr=[False, False, False, False, False, False, False, False, True, True, False, False, False, False], attr_names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country'], binning_info={'age': {'strategy': 'kde', 'n_samples': 10, 'is_integer': np.True_}, 'fnlwgt': {'strategy': 'kde', 'n_samples': 10, 'is_integer': np.True_}, 'education-num': {'strategy': 'kde', 'n_samples': 10, 'is_integer': np.True_}, 'capital-gain': {'strategy': 'kde', 'n_samples': 10, 'is_integer': np.True_}, 'capital-loss': {'strategy': 'kde', 'n_samples': 10, 'is_integer': np.True_}, 'hours-per-week': {'strategy': 'kde', 'n_samples': 10, 'is_integer': np.True_}}, kde_distributions={'age': <scipy.stats._kde.gaussian_kde object at 0x0000012E81EE1010>, 'fnlwgt': <scipy.stats._kde.gaussian_kde object at 0x0000012E81EE3500>, 'education-num': <scipy.stats._kde.gaussian_kde object at 0x0000012E81EDB9B0>, 'capital-gain': <scipy.stats._kde.gaussian_kde object at 0x0000012E81ED8FB0>, 'capital-loss': <scipy.stats._kde.gaussian_kde object at 0x0000012E81ED8CB0>, 'hours-per-week': <scipy.stats._kde.gaussian_kde object at 0x0000012E81ED9AF0>}, label_encoders={'workclass': LabelEncoder(), 'education': LabelEncoder(), 'marital-status': LabelEncoder(), 'occupation': LabelEncoder(), 'relationship': LabelEncoder(), 'race': LabelEncoder(), 'sex': LabelEncoder(), 'native-country': LabelEncoder()}, category_maps={'age': {-1: 'nan', 0: '21', 1: '29', 2: '32', 3: '33', 4: '39', 5: '44', 6: '47', 7: '48', 8: '51', 9: '58'}, 'workclass': {-1: 'nan', 0: 'State-gov', 1: 'Self-emp-not-inc', 2: 'Private', 3: 'Federal-gov', 4: 'Local-gov', 5: '?', 6: 'Self-emp-inc', 7: 'Without-pay', 8: 'Never-worked'}, 'fnlwgt': {-1: 'nan', 0: '8770', 1: '37051', 2: '56820', 3: '82343', 4: '122298', 5: '152728', 6: '192465', 7: '199046', 8: '207408', 9: '439149'}, 'education': {-1: 'nan', 0: 'Bachelors', 1: 'HS-grad', 2: '11th', 3: 'Masters', 4: '9th', 5: 'Some-college', 6: 'Assoc-acdm', 7: 'Assoc-voc', 8: '7th-8th', 9: 'Doctorate', 10: 'Prof-school', 11: '5th-6th', 12: '10th', 13: '1st-4th', 14: 'Preschool', 15: '12th'}, 'education-num': {-1: 'nan', 0: '3', 1: '4', 2: '8', 3: '9', 4: '10', 5: '11', 6: '12', 7: '13', 8: '14', 9: '16'}, 'marital-status': {-1: 'nan', 0: 'Never-married', 1: 'Married-civ-spouse', 2: 'Divorced', 3: 'Married-spouse-absent', 4: 'Separated', 5: 'Married-AF-spouse', 6: 'Widowed'}, 'occupation': {-1: 'nan', 0: 'Adm-clerical', 1: 'Exec-managerial', 2: 'Handlers-cleaners', 3: 'Prof-specialty', 4: 'Other-service', 5: 'Sales', 6: 'Craft-repair', 7: 'Transport-moving', 8: 'Farming-fishing', 9: 'Machine-op-inspct', 10: 'Tech-support', 11: '?', 12: 'Protective-serv', 13: 'Armed-Forces', 14: 'Priv-house-serv'}, 'relationship': {-1: 'nan', 0: 'Not-in-family', 1: 'Husband', 2: 'Wife', 3: 'Own-child', 4: 'Unmarried', 5: 'Other-relative'}, 'race': {-1: 'nan', 0: 'White', 1: 'Black', 2: 'Asian-Pac-Islander', 3: 'Amer-Indian-Eskimo', 4: 'Other'}, 'sex': {-1: 'nan', 0: 'Male', 1: 'Female'}, 'capital-gain': {-1: 'nan', 0: '-2139', 1: '-1124', 2: '-864', 3: '-480', 4: '-151', 5: '-9', 6: '231', 7: '371', 8: '725', 9: '4408'}, 'capital-loss': {-1: 'nan', 0: '-124', 1: '-113', 2: '-64', 3: '-26', 4: '-11', 5: '-5', 6: '15', 7: '27', 8: '61', 9: '93'}, 'hours-per-week': {-1: 'nan', 0: '20', 1: '30', 2: '33', 3: '35', 4: '38', 5: '39', 6: '40', 7: '41', 8: '42', 9: '54'}, 'native-country': {-1: 'nan', 0: 'United-States', 1: 'Cuba', 2: 'Jamaica', 3: 'India', 4: '?', 5: 'Mexico', 6: 'South', 7: 'Puerto-Rico', 8: 'Honduras', 9: 'England', 10: 'Canada', 11: 'Germany', 12: 'Iran', 13: 'Philippines', 14: 'Italy', 15: 'Poland', 16: 'Columbia', 17: 'Cambodia', 18: 'Thailand', 19: 'Ecuador', 20: 'Laos', 21: 'Taiwan', 22: 'Haiti', 23: 'Portugal', 24: 'Dominican-Republic', 25: 'El-Salvador', 26: 'France', 27: 'Guatemala', 28: 'China', 29: 'Japan', 30: 'Yugoslavia', 31: 'Peru', 32: 'Outlying-US(Guam-USVI-etc)', 33: 'Scotland', 34: 'Trinadad&Tobago', 35: 'Greece', 36: 'Nicaragua', 37: 'Vietnam', 38: 'Hong', 39: 'Ireland', 40: 'Hungary', 41: 'Holand-Netherlands'}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T17:09:47.732388Z",
     "start_time": "2024-12-04T17:09:47.726571Z"
    }
   },
   "cell_type": "code",
   "source": "corr_matrix",
   "id": "20b55a9e1e91a8b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "         3.23821747e-03,  0.00000000e+00, -8.65481335e-02,\n",
       "         1.31005186e-02, -2.26928347e-02,  6.28912563e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.87420798e-03],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  3.23821747e-03,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  2.01870765e-02,\n",
       "        -3.75523035e-02,  1.36577585e-02,  1.00346755e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  9.34480609e-02],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -8.65481335e-02,  0.00000000e+00,\n",
       "         2.01870765e-02,  0.00000000e+00,  1.00000000e+00,\n",
       "        -1.27391081e-02, -3.28933866e-01, -1.20903828e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  8.45054844e-04],\n",
       "       [ 0.00000000e+00,  1.31005186e-02,  0.00000000e+00,\n",
       "        -3.75523035e-02,  0.00000000e+00, -1.27391081e-02,\n",
       "         1.00000000e+00, -4.46117557e-02, -2.23358740e-03,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  3.41044748e-03],\n",
       "       [ 0.00000000e+00, -2.26928347e-02,  0.00000000e+00,\n",
       "         1.36577585e-02,  0.00000000e+00, -3.28933866e-01,\n",
       "        -4.46117557e-02,  1.00000000e+00, -8.35769795e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.83358743e-02],\n",
       "       [ 0.00000000e+00,  6.28912563e-02,  0.00000000e+00,\n",
       "         1.00346755e-02,  0.00000000e+00, -1.20903828e-01,\n",
       "        -2.23358740e-03, -8.35769795e-02,  1.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.72741560e-01],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -1.87420798e-03,  0.00000000e+00,\n",
       "         9.34480609e-02,  0.00000000e+00,  8.45054844e-04,\n",
       "         3.41044748e-03, -1.83358743e-02,  1.72741560e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T17:09:35.800303Z",
     "start_time": "2024-12-04T17:09:35.457904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from data_generator.main import generate_data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = generate_data(\n",
    "    correlation_matrix=corr_matrix,\n",
    "    data_schema=schema,\n",
    "    prop_protected_attr=0.4,\n",
    "    nb_groups=10,\n",
    "    max_group_size=400,\n",
    "    categorical_outcome=True,\n",
    "    use_cache=False,\n",
    "    corr_matrix_randomness=0.0)\n",
    "\n",
    "print(f\"Generated {len(data.dataframe)} samples in {data.nb_groups} groups\")\n",
    "print(f\"Collisions: {data.collisions}\")"
   ],
   "id": "e9791244e68d0abd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data:   0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdata_generator\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmain\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m generate_data\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LabelEncoder\n\u001B[1;32m----> 4\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcorrelation_matrix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcorr_matrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_schema\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprop_protected_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnb_groups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_group_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m400\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcategorical_outcome\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcorr_matrix_randomness\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerated \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(data\u001B[38;5;241m.\u001B[39mdataframe)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m samples in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata\u001B[38;5;241m.\u001B[39mnb_groups\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m groups\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCollisions: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata\u001B[38;5;241m.\u001B[39mcollisions\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ClearBias\\data_generator\\main.py:1052\u001B[0m, in \u001B[0;36mgenerate_data\u001B[1;34m(gen_order, correlation_matrix, W, nb_groups, nb_attributes, min_number_of_classes, max_number_of_classes, prop_protected_attr, min_group_size, max_group_size, min_similarity, max_similarity, min_alea_uncertainty, max_alea_uncertainty, min_epis_uncertainty, max_epis_uncertainty, min_frequency, max_frequency, min_diff_subgroup_size, max_diff_subgroup_size, min_granularity, max_granularity, min_intersectionality, max_intersectionality, categorical_outcome, nb_categories_outcome, use_cache, corr_matrix_randomness, data_schema)\u001B[0m\n\u001B[0;32m   1050\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m collision_tracker\u001B[38;5;241m.\u001B[39mis_collision(possibility):\n\u001B[0;32m   1051\u001B[0m     collision_tracker\u001B[38;5;241m.\u001B[39madd_combination(possibility)\n\u001B[1;32m-> 1052\u001B[0m     group \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_group\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1053\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgranularity\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mintersectionality\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1054\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpossibility\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattr_categories\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msets_attr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcorrelation_matrix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgen_order\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mW\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1055\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubgroup_bias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcorr_matrix_randomness\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_similarity\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_similarity\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_alea_uncertainty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1056\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_alea_uncertainty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1057\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmin_epis_uncertainty\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_epis_uncertainty\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_frequency\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_frequency\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1058\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmin_diff_subgroup_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_diff_subgroup_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_group_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_group_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattr_names\u001B[49m\n\u001B[0;32m   1059\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1060\u001B[0m     results\u001B[38;5;241m.\u001B[39mappend(group)\n\u001B[0;32m   1061\u001B[0m     pbar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ClearBias\\data_generator\\main.py:852\u001B[0m, in \u001B[0;36mcreate_group\u001B[1;34m(granularity, intersectionality, possibility, attr_categories, sets_attr, correlation_matrix, gen_order, W, subgroup_bias, corr_matrix_randomness, min_similarity, max_similarity, min_alea_uncertainty, max_alea_uncertainty, min_epis_uncertainty, max_epis_uncertainty, min_frequency, max_frequency, min_diff_subgroup_size, max_diff_subgroup_size, min_group_size, max_group_size, attr_names)\u001B[0m\n\u001B[0;32m    839\u001B[0m generator \u001B[38;5;241m=\u001B[39m IndividualsGenerator(\n\u001B[0;32m    840\u001B[0m     schema\u001B[38;5;241m=\u001B[39mattr_categories,\n\u001B[0;32m    841\u001B[0m     graph\u001B[38;5;241m=\u001B[39mcorrelation_matrix,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    848\u001B[0m     corr_matrix_randomness\u001B[38;5;241m=\u001B[39mcorr_matrix_randomness\n\u001B[0;32m    849\u001B[0m )\n\u001B[0;32m    851\u001B[0m \u001B[38;5;66;03m# Generate dataset for subgroup 1 and subgroup 2\u001B[39;00m\n\u001B[1;32m--> 852\u001B[0m subgroup1_data \u001B[38;5;241m=\u001B[39m generator\u001B[38;5;241m.\u001B[39mgenerate_dataset_with_outcome(subgroup1_size, subgroup1_vals, is_subgroup1\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    853\u001B[0m subgroup1_individuals \u001B[38;5;241m=\u001B[39m [sample \u001B[38;5;28;01mfor\u001B[39;00m sample, _, _, _ \u001B[38;5;129;01min\u001B[39;00m subgroup1_data]\n\u001B[0;32m    854\u001B[0m subgroup1_individuals_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(subgroup1_individuals, columns\u001B[38;5;241m=\u001B[39mattr_names)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ClearBias\\data_generator\\main.py:608\u001B[0m, in \u001B[0;36mIndividualsGenerator.generate_dataset_with_outcome\u001B[1;34m(self, n_samples, predetermined_values, is_subgroup1)\u001B[0m\n\u001B[0;32m    605\u001B[0m     final_probs \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m final_probs\u001B[38;5;241m.\u001B[39msum(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    607\u001B[0m     \u001B[38;5;66;03m# Generate values\u001B[39;00m\n\u001B[1;32m--> 608\u001B[0m     samples[mask, attr] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchoice\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m final_probs])\n\u001B[0;32m    610\u001B[0m \u001B[38;5;66;03m# Prepare features and generate outcomes\u001B[39;00m\n\u001B[0;32m    611\u001B[0m X \u001B[38;5;241m=\u001B[39m (samples \u001B[38;5;241m-\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(samples, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)) \u001B[38;5;241m/\u001B[39m (np\u001B[38;5;241m.\u001B[39mstd(samples, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1e-8\u001B[39m)\n",
      "File \u001B[1;32mnumpy\\\\random\\\\mtrand.pyx:994\u001B[0m, in \u001B[0;36mnumpy.random.mtrand.RandomState.choice\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: probabilities contain NaN"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def compare_datasets(df1, df2):\n",
    "    results = {}\n",
    "\n",
    "    for column in df1.columns:\n",
    "        if np.issubdtype(df1[column].dtype, np.number):\n",
    "            # KS test\n",
    "            ks_stat, ks_pval = stats.ks_2samp(df1[column], df2[column])\n",
    "\n",
    "            # Summary statistics\n",
    "            mean_diff = abs(df1[column].mean() - df2[column].mean())\n",
    "            std_ratio = df1[column].std() / df2[column].std()\n",
    "\n",
    "            # Distribution comparison\n",
    "            hist1, bins = np.histogram(df1[column], bins='auto', density=True)\n",
    "            hist2, _ = np.histogram(df2[column], bins=bins, density=True)\n",
    "            js_div = jensenshannon(hist1 + 1e-10, hist2 + 1e-10)\n",
    "\n",
    "            results[column] = {\n",
    "                'ks_statistic': ks_stat,\n",
    "                'ks_pvalue': ks_pval,\n",
    "                'mean_difference': mean_diff,\n",
    "                'std_ratio': std_ratio,\n",
    "                'jensen_shannon_div': js_div\n",
    "            }\n",
    "\n",
    "    # Correlation structure comparison\n",
    "    corr1 = df1.corr()\n",
    "    corr2 = df2.corr()\n",
    "    corr_diff = np.abs(corr1 - corr2).mean().mean()\n",
    "    results['correlation_matrix_difference'] = corr_diff\n",
    "\n",
    "    return results"
   ],
   "id": "78c344ed4970211c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
