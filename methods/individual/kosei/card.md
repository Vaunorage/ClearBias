### **Title**
An efficient discrimination discovery method for fairness testing.

### **Metric**
The method relies on **individual discrimination**.

*   **Definition:** Individual discrimination is defined as occurring when a machine learning model gives different results to two similar individuals who only differ in their protected attributes (e.g., gender, race).
*   **Formalization (from Definition 1):** A data item `I` is considered discriminatory if there exists a counterpart `I'` that differs from `I` only in a set of protected attributes `Q`, and the difference in the model's output `|f(I) - f(I')|` is greater than a pre-determined threshold `Î³`.

### **Location**
The method finds discrimination in **machine learning models (classifiers)**. It is a black-box testing approach, meaning it does not need access to the model's internal structure but queries it with different inputs to observe its behavior.

### **What they find**
The method aims to find and report **individual discriminatory data items**. These are specific input data instances (test cases) that trigger unfair behavior from the model, as defined by the individual discrimination metric. It does not find discriminated groups but rather individual instances of discrimination.

### **What does the method return in terms of data structure?**
The method returns a **set of discriminatory data items**. As described in Algorithms 1 and 3, the output is a collection (like a list or set, denoted as `D` or `D_local`) of data items that have been evaluated and confirmed to be discriminatory.

### **Performance**
The performance of KOSEI was evaluated by comparing it against a landmark technique, AEQUITAS, on which it is based. The evaluation used three datasets, three types of classifiers, and was measured on detection ability and efficiency.

*   **Discrimination Detection:** KOSEI significantly outperformed AEQUITAS, detecting **5,084.8% more discriminatory instances** on average across all experimental configurations.
*   **Execution Time:** KOSEI was much more efficient, running on average in just **7.5% of the execution time** of AEQUITAS (or 13.3 times faster).
*   **Test Case Quality:**
    *   **Precision:** KOSEI's generated test cases were **3.04 times more likely** to be discriminatory (higher precision) than those generated by AEQUITAS.
    *   **Duplication:** KOSEI is designed to avoid evaluating duplicated test cases, whereas the evaluation showed that in AEQUITAS, **98.8% of evaluated data were duplicates**, leading to inefficiency.

# KOSEI Algorithm Documentation

## Implementation

The KOSEI (Knowledge-guided Optimization-based Search for Effective Instances) algorithm is an individual fairness testing method designed to identify discriminatory instances in machine learning models. Here's a detailed breakdown of its input parameters and output.

## Input Parameters

### Main Parameters

**`model`**: `Optional[Union[Callable[[np.ndarray], Any], str]] = None`
- A callable model that takes a numpy array as input and returns a prediction
- Can also be a string specifying the model type to train (e.g., 'rf' for Random Forest)
- If None, a model will be trained using the provided discrimination_data

**`discrimination_data`**: `Optional[DiscriminationData] = None`
- A DiscriminationData object containing dataset information
- Includes training data, attribute columns, sensitive attributes, and input bounds
- If provided, other dataset-related parameters are extracted from this object

**`protected_attribute_indices`**: `Optional[List[int]] = None`
- List of indices for protected attributes (used if discrimination_data is None)
- Example: `[0, 1]` indicates the first two attributes are protected

**`attribute_domains`**: `Optional[Dict[int, tuple]] = None`
- Dictionary mapping attribute indices to their domains (min, max)
- Example: `{0: (0, 1), 1: (0, 5)}` means attribute 0 has domain [0,1] and attribute 1 has domain [0,5]

**`total_attributes`**: `Optional[int] = None`
- Total number of attributes (used if discrimination_data is None)
- Example: 10 for a dataset with 10 features

**`gamma`**: `float = 0.0`
- Threshold for determining discrimination
- Default is 0.0, meaning any difference in prediction is considered discriminatory

**`model_type`**: `str = 'rf'`
- Type of model to train if no model is provided
- Default is 'rf' (Random Forest)
- Other options could include 'lr' (Logistic Regression), 'svm', etc.

**`model_params`**: `Optional[Dict] = None`
- Parameters for the model to train if no model is provided
- Example: `{'n_estimators': 100, 'max_depth': 5}` for Random Forest

### Search Parameters

**`num_samples`**: `int = 1000`
- Number of random samples to generate in the global search phase
- Higher values increase the chance of finding discriminatory instances but take longer

**`local_search_limit`**: `int = 500`
- Maximum number of iterations for the local search phase
- Controls how thoroughly the algorithm explores around initial seeds

**`random_seed`**: `int = 42`
- Seed for random number generation to ensure reproducibility
- Default is 42

**`max_runtime_seconds`**: `int = 3600`
- Maximum runtime in seconds (default: 1 hour)
- Algorithm will terminate early if this time limit is reached

## Output

The algorithm returns a tuple containing two elements:

**`results_df`**: `pd.DataFrame`
- A DataFrame containing all discriminatory pairs found
- Each row represents an individual instance that is part of a discriminatory pair

**`metrics`**: `Dict`
- A dictionary with summary metrics about the discrimination found

### Example Output DataFrame

The DataFrame has the following structure:

```python
# Example results_df structure
"""
   attr_1  attr_2  ...  attr_n  indv_key  outcome  couple_key  diff_outcome  case_id  TSN  DSN  SUR  DSS
0     0.0     1.0  ...     2.0    0|1|2        1  0|1|2-0|0|2            1        0  500   45  0.09  2.5
1     0.0     0.0  ...     2.0    0|0|2        0  0|1|2-0|0|2            1        0  500   45  0.09  2.5
2     1.0     0.0  ...     1.0    1|0|1        1  1|0|1-1|1|1            1        1  500   45  0.09  2.5
3     1.0     1.0  ...     1.0    1|1|1        0  1|0|1-1|1|1            1        1  500   45  0.09  2.5
...    ...     ...  ...     ...       ...      ...         ...          ...      ...  ...  ...  ...  ...
"""
```

Where:
- **`attr_1, attr_2, ..., attr_n`**: The attribute values for each instance
- **`indv_key`**: A string representation of the instance (concatenated attribute values)
- **`outcome`**: The model's prediction for this instance
- **`couple_key`**: A key linking the two instances in a discriminatory pair
- **`diff_outcome`**: The absolute difference in outcomes between the paired instances
- **`case_id`**: An identifier for each discriminatory pair
- **`TSN`**: Total Sample Number - total number of samples tested
- **`DSN`**: Discriminatory Sample Number - total number of discriminatory pairs found
- **`SUR`**: Success Rate (DSN/TSN) - ratio of discriminatory pairs to total samples
- **`DSS`**: Discriminatory Sample Search time - average time to find a discriminatory pair

For each discriminatory pair, there are two rows in the DataFrame (the original instance and the perturbed instance).

### Example Metrics Dictionary

```python
# Example metrics structure
metrics = {
    'TSN': 1500,                # Total Sample Number
    'DSN': 45,                  # Discriminatory Sample Number
    'SUR': 0.03,                # Success Rate (3% of tested inputs showed discrimination)
    'DSS': 2.5,                 # Average search time per discriminatory sample (seconds)
    'total_time': 112.5,        # Total runtime in seconds
    'dsn_by_attr_value': {
        'total': {'TSN': 1500, 'DSN': 45},
        'attr_0_0': {'TSN': 200, 'DSN': 15, 'SUR': 0.075, 'DSS': 2.5},  # Attribute 0 with value 0
        'attr_0_1': {'TSN': 300, 'DSN': 30, 'SUR': 0.10, 'DSS': 2.5},   # Attribute 0 with value 1
        # ... other attribute-value combinations
    }
}
```

Where:
- **`TSN`**: Total Sample Number - number of samples tested
- **`DSN`**: Discriminatory Sample Number - number of discriminatory pairs found
- **`SUR`**: Success Rate (DSN/TSN) - ratio of discriminatory pairs to total samples
- **`DSS`**: Discriminatory Sample Search time - average time to find a discriminatory pair
- **`total_time`**: Total runtime in seconds
- **`dsn_by_attr_value`**: Breakdown of discrimination by attribute values

## Example Usage

```python
from data_generator.main import get_real_data
from methods.individual.kosei.main import run_kosei

# Load a dataset (e.g., Adult Income dataset)
discrimination_data, data_schema = get_real_data('adult', use_cache=True)

# Run KOSEI with default parameters
results_df, metrics = run_kosei(
    discrimination_data=discrimination_data,
    num_samples=100,
    local_search_limit=50
)

# Print metrics summary
print(f"Testing Metrics: {metrics}")

# Analyze discriminatory pairs
print(f"Found {metrics['DSN']} discriminatory pairs")
print(results_df.head())

# Get unique discriminatory pairs
unique_pairs = results_df['case_id'].unique()
print(f"Number of unique discriminatory pairs: {len(unique_pairs)}")
```

## Algorithm Overview

The KOSEI algorithm works in two phases:

1. **Global Search**: Randomly samples instances to find initial discriminatory seeds
2. **Local Search**: Explores around these seeds to find more discriminatory instances

This approach efficiently identifies individual fairness violations in machine learning models, helping detect bias against protected attributes.