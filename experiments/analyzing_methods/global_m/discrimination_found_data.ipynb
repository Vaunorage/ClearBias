{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Premise :\n",
    "Discriminations found in data vs found in trained model : We must distinguish between the discriminations that are in the model and not in the data. Someone who runs an analysis might be more interested in a model that performs better in finding discrimination in data. Using an intermediary model like many of them do might yield results that are not real.\n",
    "\n",
    "- Proportion of discriminations from the data (nb discrimination / nb unique found)\n",
    "- Proportion of new discrimination not in data (nb discrimination / nb unique found)"
   ],
   "id": "63b1b0fd68e809cd"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-11T23:04:17.927038Z",
     "start_time": "2025-04-11T23:04:15.533155Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from data_generator.main import generate_data\n",
    "from path import HERE\n",
    "import sqlite3\n",
    "\n",
    "data_obj = generate_data()\n",
    "\n",
    "DB_PATH = HERE.joinpath(\"experiments/analyzing_methods/global/global_testing_res.db\")\n",
    "\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "df_res = pd.read_sql(\"SELECT * FROM main.table_fe2d9c73c8d144c3958cd9c0382ad043_results\", conn)\n",
    "df_test = pd.read_sql(\"SELECT * FROM main.table_fe2d9c73c8d144c3958cd9c0382ad043_testdata\", conn)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached data\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T23:04:19.711942Z",
     "start_time": "2025-04-11T23:04:19.683180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Tuple\n",
    "from functools import lru_cache\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=4096)\n",
    "def matches_pattern(pattern: str, value: str) -> bool:\n",
    "    \"\"\"Convert the pattern with * wildcards to regex and match against value.\"\"\"\n",
    "    import re\n",
    "    # Escape special regex characters except *\n",
    "    regex_pattern = re.escape(pattern).replace('\\\\*', '.*')\n",
    "    return bool(re.match(f'^{regex_pattern}$', value))\n",
    "\n",
    "\n",
    "def is_individual_part_of_the_original_indv(indv_key, indv_key_list):\n",
    "    return indv_key in indv_key_list\n",
    "\n",
    "\n",
    "def is_couple_part_of_a_group(couple_key, group_key_list):\n",
    "    res = []\n",
    "\n",
    "    couple_key_elems = couple_key.split('-')\n",
    "    if len(couple_key_elems) != 2:\n",
    "        print(f\"Warning: Unexpected couple key format: {couple_key}\")\n",
    "        return res\n",
    "\n",
    "    opt1 = f\"{couple_key_elems[0]}-{couple_key_elems[1]}\"\n",
    "    opt2 = f\"{couple_key_elems[1]}-{couple_key_elems[0]}\"\n",
    "\n",
    "    for grp_key in group_key_list:\n",
    "        if matches_pattern(grp_key, opt1) or matches_pattern(grp_key, opt2):\n",
    "            res.append(grp_key)\n",
    "    return res\n",
    "\n",
    "\n",
    "def evaluate_discrimination_detection(\n",
    "        synthetic_data: pd.DataFrame,\n",
    "        results_df: pd.DataFrame\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Optimized evaluation of discrimination detection with fixed metrics calculation.\"\"\"\n",
    "    if results_df.empty:\n",
    "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    # Convert to string type once\n",
    "    synthetic_data = synthetic_data.astype({\n",
    "        'indv_key': str,\n",
    "        'group_key': str,\n",
    "        'subgroup_key': str\n",
    "    })\n",
    "\n",
    "    results_df = results_df.astype({\n",
    "        'indv_key': str,\n",
    "        'couple_key': str\n",
    "    })\n",
    "\n",
    "    # Create a DataFrame for group-level analysis\n",
    "    unique_groups = synthetic_data['group_key'].unique()\n",
    "\n",
    "    def analyze_group(group_key: str) -> pd.Series:\n",
    "        # Get individuals in this group from synthetic data\n",
    "        group_synthetic_indv = set(\n",
    "            synthetic_data[synthetic_data['group_key'] == group_key]['indv_key']\n",
    "        )\n",
    "\n",
    "        # Split group key into its two patterns\n",
    "        group_patterns = group_key.split('-')\n",
    "        pattern1, pattern2 = group_patterns[0], group_patterns[1]\n",
    "\n",
    "        # Find exact individual matches in results\n",
    "        exact_indv_matches = [\n",
    "            key for key in results_df['indv_key'].unique()\n",
    "            if is_individual_part_of_the_original_indv(key, group_synthetic_indv)\n",
    "        ]\n",
    "\n",
    "        # For couples, we need to check if both individuals in the couple are exact matches\n",
    "        exact_couple_matches = []\n",
    "        for couple_key in results_df['couple_key'].unique():\n",
    "            indv1, indv2 = couple_key.split('-')\n",
    "            if (is_individual_part_of_the_original_indv(indv1, group_synthetic_indv) and\n",
    "                    is_individual_part_of_the_original_indv(indv2, group_synthetic_indv)):\n",
    "                exact_couple_matches.append(couple_key)\n",
    "\n",
    "        # Find new individuals matching either group pattern but not in original data\n",
    "        new_group_indv = [\n",
    "            key for key in results_df['indv_key'].unique()\n",
    "            if (matches_pattern(pattern1, key) or matches_pattern(pattern2, key))\n",
    "               and key not in exact_indv_matches\n",
    "        ]\n",
    "\n",
    "        # Find new couples matching group pattern but not in exact matches\n",
    "        new_group_couples = [\n",
    "            key for key in results_df['couple_key'].unique()\n",
    "            if is_couple_part_of_a_group(key, [group_key])\n",
    "               and key not in exact_couple_matches\n",
    "        ]\n",
    "\n",
    "        return pd.Series({\n",
    "            'group_key': group_key,\n",
    "            'synthetic_group_size': len(group_synthetic_indv),\n",
    "            'individuals_part_of_original_data': exact_indv_matches,\n",
    "            'couples_part_of_original_data': exact_couple_matches,\n",
    "            'new_individuals_part_of_a_group_regex': new_group_indv,\n",
    "            'new_couples_part_of_a_group_regex': new_group_couples,\n",
    "            'num_exact_individual_matches': len(exact_indv_matches),\n",
    "            'num_exact_couple_matches': len(exact_couple_matches),\n",
    "            'num_new_group_individuals': len(new_group_indv),\n",
    "            'num_new_group_couples': len(new_group_couples)\n",
    "        })\n",
    "\n",
    "    # Create group analysis DataFrame\n",
    "    group_analysis_df = pd.DataFrame([\n",
    "        analyze_group(group_key) for group_key in unique_groups\n",
    "    ])\n",
    "\n",
    "    # Process results additions\n",
    "    def process_results_row(row):\n",
    "        # Check if individual is an exact match in any group\n",
    "        is_original = any(\n",
    "            is_individual_part_of_the_original_indv(row['indv_key'],\n",
    "                                                    synthetic_data[synthetic_data['group_key'] == group_key][\n",
    "                                                        'indv_key'])\n",
    "            for group_key in unique_groups\n",
    "        )\n",
    "\n",
    "        # Check which groups the individual matches patterns for\n",
    "        individual_groups = []\n",
    "        for group_key in unique_groups:\n",
    "            pattern1, pattern2 = group_key.split('-')\n",
    "            if matches_pattern(pattern1, row['indv_key']) or matches_pattern(pattern2, row['indv_key']):\n",
    "                individual_groups.append(group_key)\n",
    "\n",
    "        # Check which groups the couple matches patterns for\n",
    "        couple_groups = [\n",
    "            group_key for group_key in unique_groups\n",
    "            if is_couple_part_of_a_group(row['couple_key'], [group_key])\n",
    "        ]\n",
    "\n",
    "        return pd.Series({\n",
    "            'is_original_data': is_original,\n",
    "            'is_individual_part_of_a_group': len(individual_groups) > 0,\n",
    "            'is_couple_part_of_a_group': len(couple_groups) > 0,\n",
    "            'matching_groups': individual_groups\n",
    "        })\n",
    "\n",
    "    # Apply the processing to results data\n",
    "    results_additions = results_df.apply(process_results_row, axis=1)\n",
    "    results_df = pd.concat([results_df, results_additions], axis=1)\n",
    "\n",
    "    # Create a summary DataFrame\n",
    "    summary_df = pd.DataFrame({\n",
    "        'total_synthetic_records': len(synthetic_data),\n",
    "        'total_result_records': len(results_df),\n",
    "        'total_groups': len(unique_groups),\n",
    "        'avg_group_size': group_analysis_df['synthetic_group_size'].mean(),\n",
    "        'avg_exact_matches_per_group': group_analysis_df['num_exact_individual_matches'].mean(),\n",
    "        'avg_new_matches_per_group': group_analysis_df['num_new_group_individuals'].mean()\n",
    "    }, index=[0])\n",
    "\n",
    "    return group_analysis_df, results_df, summary_df\n"
   ],
   "id": "2ae04c148973a39e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T23:08:35.074178Z",
     "start_time": "2025-04-11T23:04:34.484183Z"
    }
   },
   "cell_type": "code",
   "source": "eval_results, group_details = evaluate_discrimination_detection(df_test, df_res)\n",
   "id": "617e51981c2e6dfc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c0fce937225ff97f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
