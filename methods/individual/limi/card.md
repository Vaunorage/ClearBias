### **Title**
Latent Imitator: Generating Natural Individual Discriminatory Instances for Black-Box Fairness Testing

### **Metric**
The method does not rely on a standard explainability metric (like SHAP or LIME). Instead, its core mechanism is based on the **geometric properties of a Generative Adversarial Network's (GAN) latent space**.

1.  **Surrogate Decision Boundary**: The method first trains a GAN on the dataset. It then generates a large number of synthetic data points and gets their prediction labels from the target black-box model. Using these latent vectors and their corresponding model predictions, it trains a simple linear classifier (an SVM) in the latent space. This classifier acts as a **surrogate decision boundary**.

2.  **Proximity to Boundary**: The primary "metric" for finding discrimination is the **proximity of a latent vector to this surrogate boundary**. The hypothesis is that instances near the decision boundary are most likely to have their prediction flipped with a small perturbation.

3.  **Probing**: For a given latent vector, the method calculates its projection directly onto the surrogate boundary and also probes two nearby points on either side. These three latent vectors are then converted into data instances and tested for discrimination.

### **Individual discrimination, group, subgroup discrimination (granularity and intersectionality)**
-   **Primary Focus (Granularity)**: The method is explicitly designed for **individual fairness testing**. It aims to find specific pairs of instances `(x, x')` that are identical except for a protected attribute but receive different model predictions. The paper argues this is a more granular and powerful approach than group fairness, as it can detect discrimination that group metrics might miss.

-   **Intersectionality (Subgroup)**: While the main experiments focus on a single protected attribute at a time, the paper demonstrates in Section 6 and Table 7 that the framework can be extended to handle **intersectional discrimination**. It evaluates its performance when testing for discrimination across combinations of multiple protected attributes simultaneously (e.g., `gender & race`, `gender & age`).

### **Location**
The method attempts to find discrimination in the **target machine learning model's behavior**.

The search for discriminatory instances does not happen in the original data space directly. Instead, it operates primarily in the **semantic latent space of a pre-trained Generative Adversarial Network (GAN)**. By approximating the model's decision boundary within this latent space, it identifies promising candidate regions. The final discriminatory instances are then generated from these latent vectors for testing against the model.

### **What they find**
The method finds and generates **natural individual discriminatory instances**.

Specifically, it aims to find a data instance `x` (e.g., a loan application) such that if its protected attribute is changed to create a new instance `x'` (e.g., changing gender from 'female' to 'male'), the model's prediction changes (`f(x) != f(x')`).

A key contribution is the **naturalness** of these instances. Because they are generated by a GAN trained on the real data distribution, they are claimed to be more realistic and less likely to violate real-world constraints compared to instances generated by other methods.

### **What does the method return in terms of data structure?**
The method returns a **set of individual discriminatory instances (`D_idi`)**. Each element in this set is a single data record (e.g., a row from a table or an image) that has been confirmed to cause a discriminatory outcome. That is, for each instance in the output set, flipping its protected attribute value results in a different prediction from the model.

### **Performance**
The method's performance was evaluated against 6 other state-of-the-art fairness testing methods on four tabular datasets and three model types (DNN, RF, SVM). The evaluation was based on effectiveness, efficiency, naturalness, and utility.

-   **Evaluation Metrics**:
    -   **Effectiveness**: `#D_idi` (total number of discriminatory instances found in a fixed time).
    -   **Efficiency**: `EGS` (number of discriminatory instances found per second).
    -   **Naturalness**: `ATN` (Average Tabular Naturalness), a metric measuring the statistical similarity between the generated data and the original data distribution.
    -   **Utility**: Improvement in fairness metrics (`IF_r`, `IF_o`, `SPD`, `AOD`) after retraining the model on the instances generated by the method.

-   **Results**:
    -   **Effectiveness & Efficiency**: LIMI significantly outperformed other baselines, generating on average **9.42 times more** discriminatory instances at a speed **8.71 times faster**.
    -   **Naturalness**: The instances generated by LIMI were quantifiably more natural, showing an average **19.65% improvement** in the ATN score compared to other methods.
    -   **Utility for Fairness Improvement**: Retraining a model with the data generated by LIMI led to substantial fairness improvements:
        -   **45.67%** on Individual Fairness (IF_r)
        -   **32.81%** on Individual Fairness (IF_o)
        -   **9.86%** on Group Fairness (SPD)
        -   **28.38%** on Group Fairness (AOD)