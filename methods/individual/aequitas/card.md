### Title: AEQUITAS : Automated Directed Fairness Testing

### Metric: What metric does the method rely on to find discrimination?
The method, AEQUITAS, relies on **individual fairness**. The paper states, "we focus towards individual fairness, as it is critical for eliminating societal bias and aim to check for discrimination that might violate individual fairness [2]."

This is formally defined in **Definition 4.1 (Discriminatory Input and fairness)**, where an input `I` is considered discriminatory if another input `I'`, which is identical to `I` except for its values on protected attributes (e.g., gender), receives a significantly different output from the model (`|f(I) − f(I')| > γ`).

### Location: Where does this method try to find discrimination models or data?
The method finds discrimination in the **machine learning model** itself. It operates as a black-box testing approach. The abstract clearly states, "For a given machine-learning model and a set of sensitive input parameters, our AEQUITAS approach automatically discovers discriminatory inputs that highlight fairness violation." The methodology involves systematically generating inputs and observing the model's outputs to uncover biased behavior, rather than analyzing the training data directly.

### What they find: What exactly does this method try to find and what does the method return?
- **What it finds**: The method aims to find **individual discriminatory inputs**. These are specific input examples that, when compared to a minimally different counterpart (differing only on a sensitive attribute), receive a different classification from the model, thus exposing a fairness violation.

- **What it returns**: The method returns a **set of discriminatory inputs**. The algorithms described in the paper (e.g., `GLOBAL_EXP` and `LOCAL_EXP`) build and return a set (`disc_inps` or `Test`) containing the inputs that were found to cause discriminatory behavior in the model.

### Performance: How did this method's performance been evaluated and what was the result?
The performance of AEQUITAS was evaluated against six classifiers (including SVM, Random Forest, and a "Fair SVM") on the US census income dataset, with "gender" as the sensitive attribute.

The evaluation and results were as follows:

1.  **Effectiveness (Finding Discrimination)**: AEQUITAS significantly outperformed purely random testing. It was more effective by "a factor of 9.6 on average and up to a factor of 20.4". In its most advanced configuration (`fully-directed`), it generated test suites where up to **70% of the inputs were discriminatory**.

2.  **Efficiency (Speed)**: The method was much faster than random testing at finding discriminatory inputs. The `fully-directed` version was **83.27% faster on average** and up to **96.62% faster** in the best case.

3.  **Utility (Improving Fairness)**: The discriminatory inputs generated by AEQUITAS were successfully used to retrain and improve the models. This automated retraining process reduced the percentage of discriminatory inputs by an **average of 43.2%** across the tested models, with a maximum reduction of **94.36%** for the Decision Tree classifier.