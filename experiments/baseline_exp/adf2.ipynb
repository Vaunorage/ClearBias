{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_generator.main import get_real_data, generate_from_real_data\n",
    "from methods.adf.main1 import adf_fairness_testing\n",
    "from methods.utils import compare_discriminatory_groups, get_groups\n",
    "\n",
    "\n",
    "def run_experiment(seed, dataset_name):\n",
    "    # Get real data\n",
    "    data_obj, schema = get_real_data(dataset_name, use_cache=True)\n",
    "\n",
    "    # Run fairness testing on original data\n",
    "    results_df_origin, metrics_origin = adf_fairness_testing(\n",
    "        data_obj,\n",
    "        max_global=5000,\n",
    "        max_local=2000,\n",
    "        max_iter=1000,\n",
    "        cluster_num=100,\n",
    "        random_seed=seed,\n",
    "        max_runtime_seconds=400\n",
    "    )\n",
    "\n",
    "    # Get discriminatory groups from original data\n",
    "    predefined_groups_origin, nb_elements = get_groups(results_df_origin, data_obj, schema)\n",
    "\n",
    "    # Generate synthetic data with predefined groups\n",
    "    data_obj_synth, schema = generate_from_real_data(\n",
    "        dataset_name,\n",
    "        nb_groups=1,\n",
    "        predefined_groups=predefined_groups_origin,\n",
    "        use_cache=True,\n",
    "        min_alea_uncertainty=0.0,\n",
    "        max_alea_uncertainty=1.0,\n",
    "        min_epis_uncertainty=0.0,\n",
    "        max_epis_uncertainty=1.0\n",
    "    )\n",
    "\n",
    "    # Run fairness testing on synthetic data\n",
    "    results_df_synth, metrics_synth = adf_fairness_testing(\n",
    "        data_obj_synth,\n",
    "        max_global=10000,\n",
    "        max_local=2000,\n",
    "        max_iter=2000,\n",
    "        cluster_num=100,\n",
    "        random_seed=seed,\n",
    "        max_runtime_seconds=600\n",
    "    )\n",
    "\n",
    "    # Get discriminatory groups from synthetic data\n",
    "    predefined_groups_synth, nb_elements_synth = get_groups(results_df_synth, data_obj, schema)\n",
    "\n",
    "    # Compare discriminatory groups\n",
    "    comparison_results = compare_discriminatory_groups(predefined_groups_origin, predefined_groups_synth)\n",
    "\n",
    "    return {\n",
    "        'seed': seed,\n",
    "        'coverage_ratio': comparison_results['coverage_ratio'],\n",
    "        'total_groups_matched': comparison_results['total_groups_matched'],\n",
    "        'total_original_groups': comparison_results['total_original_groups'],\n",
    "        'total_matched_size': comparison_results['total_matched_size'],\n",
    "        'total_original_size': comparison_results['total_original_size']\n",
    "    }\n",
    "\n",
    "\n",
    "def main(datasets=['bank'], num_experiments=10, random_seeds=None):\n",
    "    # Set random seeds if not provided\n",
    "    if random_seeds is None:\n",
    "        random_seeds = np.random.randint(0, 10000, size=num_experiments)\n",
    "\n",
    "    # Run experiments and collect results\n",
    "    results = []\n",
    "    for dataset in datasets:\n",
    "        for i, seed in enumerate(random_seeds):\n",
    "            print(f\"Running experiment on dataset {dataset}, run {i + 1}/{num_experiments} with seed {seed}\")\n",
    "            experiment_result = run_experiment(seed, dataset)\n",
    "            experiment_result['dataset'] = dataset\n",
    "            results.append(experiment_result)\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Calculate statistics per dataset\n",
    "    stats_list = []\n",
    "\n",
    "    for dataset in results_df['dataset'].unique():\n",
    "        dataset_results = results_df[results_df['dataset'] == dataset]\n",
    "\n",
    "        stats = {\n",
    "            'dataset': dataset,\n",
    "            'coverage_ratio': {\n",
    "                'mean': dataset_results['coverage_ratio'].mean(),\n",
    "                'std': dataset_results['coverage_ratio'].std(),\n",
    "                'min': dataset_results['coverage_ratio'].min(),\n",
    "                'max': dataset_results['coverage_ratio'].max()\n",
    "            },\n",
    "            'total_groups_matched': {\n",
    "                'mean': dataset_results['total_groups_matched'].mean(),\n",
    "                'std': dataset_results['total_groups_matched'].std()\n",
    "            },\n",
    "            'total_original_groups': {\n",
    "                'mean': dataset_results['total_original_groups'].mean(),\n",
    "                'std': dataset_results['total_original_groups'].std()\n",
    "            }\n",
    "        }\n",
    "\n",
    "        stats_list.append({\n",
    "            'Dataset': dataset,\n",
    "            'Metric': 'Coverage Ratio',\n",
    "            'Mean': stats['coverage_ratio']['mean'],\n",
    "            'Std Dev': stats['coverage_ratio']['std'],\n",
    "            'Min': stats['coverage_ratio']['min'],\n",
    "            'Max': stats['coverage_ratio']['max']\n",
    "        })\n",
    "\n",
    "        stats_list.append({\n",
    "            'Dataset': dataset,\n",
    "            'Metric': 'Total Groups Matched',\n",
    "            'Mean': stats['total_groups_matched']['mean'],\n",
    "            'Std Dev': stats['total_groups_matched']['std'],\n",
    "            'Min': None,\n",
    "            'Max': None\n",
    "        })\n",
    "\n",
    "        stats_list.append({\n",
    "            'Dataset': dataset,\n",
    "            'Metric': 'Total Original Groups',\n",
    "            'Mean': stats['total_original_groups']['mean'],\n",
    "            'Std Dev': stats['total_original_groups']['std'],\n",
    "            'Min': None,\n",
    "            'Max': None\n",
    "        })\n",
    "\n",
    "    stats_df = pd.DataFrame(stats_list)\n",
    "\n",
    "    return results_df, stats_df\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_experiments = 1\n",
    "\n",
    "# Set fixed random seeds for reproducibility\n",
    "random_seeds = [42]\n",
    "\n",
    "# List of datasets to test\n",
    "datasets = ['bank', 'adult']\n",
    "\n",
    "# Run experiments\n",
    "results_df, stats_df = main(datasets, num_experiments, random_seeds)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nExperiment Results:\")\n",
    "print(results_df)\n",
    "\n",
    "print(\"\\nStatistics:\")\n",
    "print(stats_df)\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv(\"experiment_results.csv\", index=False)\n",
    "stats_df.to_csv(\"experiment_statistics.csv\", index=False)\n",
    "\n",
    "# Save results by dataset\n",
    "for dataset in datasets:\n",
    "    dataset_results = results_df[results_df['dataset'] == dataset]\n",
    "    dataset_stats = stats_df[stats_df['Dataset'] == dataset]\n",
    "\n",
    "    dataset_results.to_csv(f\"experiment_results_{dataset}.csv\", index=False)\n",
    "    dataset_stats.to_csv(f\"experiment_statistics_{dataset}.csv\", index=False)\n",
    "\n",
    "print(\"\\nResults saved to CSV files.\")"
   ],
   "id": "e1a51aef7e79c61c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
